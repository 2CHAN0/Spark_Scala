{
  "metadata": {
    "name": "SparkKafkaBatch_JSONformat",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "//kafka batch sourcing\nval df \u003d spark.read\n  .format(\"kafka\")\n  .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n  .option(\"subscribe\", \"mysql_source_json_no_schema_users\")\n  .option(\"kafka.group.id\", \"spark-orc\")\n  .load()\n\nval df_cast \u003d df.selectExpr(\"cast(value as String) as value\")\nval schema \u003d spark.read.json(df_cast.as[String]).schema\nval json_df \u003d df_cast.select(from_json(col(\"value\"), schema).as(\"columns\"))\njson_df.select(\"columns.payload.*\").write.partitionBy(\"age\").orc(\"/merge_test/test08\")"
    }
  ]
}